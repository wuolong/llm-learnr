# llm-learnr

These are my notes from trying to learn more about "AI", including Large Language Models (LLMs) like GPT, from the perspective of a statistician (with a PhD), using the terminology and tools (R instead of Python) that I am familiar with.

## Build LLM from Scratch (in R)

- [Build LLM from Stratch](https://github.com/rasbt/LLMs-from-scratch) by Sebastian Raschka (2024) is excellent book that breaks down the black box of
  LLMs. The github site includes all source codes (Python, naturally) in the book.
- [Build LLM for Statisticians](./build-llm/learnllm.md): my notes for reading through the book ([pdf](./build-llm/learnllm.pdf)).
  
## Courses

- [Notes](./deepcmu.md) on [CMU Introduction to Deep Learning](https://deeplearning.cs.cmu.edu/S25/index.html)
- [Notes](./udlnotes.md) on [Understanding Deep Learning](https://udlbook.github.io/udlbook/)

## Resources

- [torch for R](https://torch.mlverse.org) ([Reference](https://torch.mlverse.org/docs/reference/))
- [Deep Learning and Scientific Computing with R torch](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/) - the companion book (I have not read it through yet)
- [Large Language Model Course](https://github.com/aofoegbu/llm-engineers-handbook)
- [Deeplearning.AI](https://www.deeplearning.ai/courses/)
